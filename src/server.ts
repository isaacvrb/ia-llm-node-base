import express from 'express';
import cors from 'cors';
import llmRoutes from './routes/llm.js';

const app = express();
const PORT = process.env.PORT || 3000;

// Middleware
app.use(cors());
app.use(express.json());

// Routes
app.use('/api/llm', llmRoutes);

// Global error handler
app.use((error: Error, req: express.Request, res: express.Response, next: express.NextFunction) => {
	console.error('Error:', error.message);
	res.status(500).json({
		error: 'Erro interno do servidor',
		message: error.message,
	});
});

// 404 handler
app.use((req, res) => {
	res.status(404).json({
		error: 'Rota n√£o encontrada',
		message: `A rota ${req.method} ${req.path} n√£o existe`,
	});
});

app.listen(PORT, () => {
	console.log(`üöÄ Servidor rodando na porta ${PORT}`);
	console.log(`üìç Endpoints dispon√≠veis:`);
	console.log(`   GET /api/llm/openai`);
	console.log(`   GET /api/llm/anthropic`);
	console.log(`   GET /api/llm/xai`);
	console.log(`   GET /api/llm/google`);
	console.log(`   GET /api/llm/groq`);
	console.log(`   GET /api/llm/ollama`);
});
